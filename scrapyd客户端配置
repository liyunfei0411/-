前言
Scrapyd通常作为守护进程运行，它侦听运行爬虫的请求，并为每个请求生成一个进程，该进程基本上执行:scrapy crawl [myspider]。

Scrapyd还并行运行多个进程，将它们分配到max_proc和max_proc_per_cpu选项提供的固定数量的插槽中，启动尽可能多的进程来处理负载。

除了调度和管理进程之外，Scrapyd还提供了一个JSON web服务来上载新的项目版本(作为egg)和调度爬虫。

Scrapyd官方文档 https://scrapyd.readthedocs.io/en/latest/index.html

划重点：通过api方式多进程执行请求，在网页端查看正在执行的任务，也能新建爬虫任务，和终止爬虫任务。

使用详解
安装
pip install scrapyd
1
依赖的库及版本：

Python 2.7 or above
Twisted 8.0 or above
Scrapy 1.0 or above
six
启动
在项目目录下，输入scrapyd即可运行，默认地址为http://localhost:6800

scrapyd
1
官方详细配置文档说明：https://scrapyd.readthedocs.io/en/latest/config.html

修改默认配置信息可以在项目下新建一个scrapyd.conf或者在scrapy.cfg中增加[scrapyd]：

[scrapyd]
# 网页和Json服务监听的IP地址，默认为127.0.0.1
bind_address = 127.0.0.1
# 监听的端口，默认为6800
http_port   = 6800
# 是否打开debug模式，默认为off
debug       = off
# 每个CPU可启用的Scrapy 进程数，默认为4
max_proc_per_cpu = 4
# 可启用的最多进程数，默认为0.如果未设置或者设为0，则使用的最多进程数=CPU数量*max_proc_per_cpu
max_proc = 0
# 项目eggs生成目录，默认为项目目录下eggs
eggs_dir    = eggs
# 项目日志生成目录，默认为项目目录下logs，如果不想要生成日志，可以直接设置成空
logs_dir    = logs
items_dir   =
# 项目dbs生成目录，默认为项目目录下dbs
dbs_dir     = dbs
# 爬取的items存储的文件夹（版本0.15.以上），默认为空，不存储。
items_dir =
# 每个爬虫保持的完成任务数，默认为5.（版本0.15.以上，以前版本中为logs_to_keep）
jobs_to_keep = 5
# 保持的完成任务进程数。默认为100.（版本0.14.以上）
finished_to_keep = 100
# 轮训请求队列的时间间隔。默认为5s，可以为浮点数
poll_interval = 5.0
# 启动子进程的模块。可以使用自定义
runner      = scrapyd.runner
# 返回可用于twisted的application，可继承于Scrapyd添加和移除自己的组件和服务。 https://twistedmatrix.com/documents/current/core/howto/application.html查看更多
application = scrapyd.app.application
launcher    = scrapyd.launcher.Launcher
# twisted的web资源，表示到scrapyd的接口。Scrapyd包含一个带有网站的界面，可以提供对应用程序的web资源的简单监视和访问。此设置必须提供twisted web资源的根类。
webroot     = scrapyd.website.Root
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
项目发布
部署主要分为两步：

将项目打包成egg
将egg通过Scrapyd的addversion.json接口上传到目标服务器
官方的部署上传接口文档：https://scrapyd.readthedocs.io/en/latest/api.html#addversion-json

小编推荐使用Scrapyd-client中的scrapyd-deploy一步上传，关于Scrapyd-client介绍：

Scrapyd-client is a client for Scrapyd. It provides the general scrapyd-client and the scrapyd-deploy utility which allows you to deploy your project to a Scrapyd server.

划重点：打包上传一步到位。

Scrapy-client安装

pip install scrapyd-client
1
部署：在项目目录下，即scrapy.cfg所在的目录下运行

scrapyd-deploy
1
正确的结果：



可能出现的错误：

（1）Deploy failed: <urlopen error [WinError 10061] 由于目标计算机积极拒绝，无法连接。



原因：Scrapyd未启动，需要先在项目目录下运行scrapyd启动项目。

（2）‘scrapyd-deploy’ 不是内部或外部命令，也不是可运行的程序或批处理文件。



解决：

进入安装python 的位置的Scripts文件夹


创建文件 scrapyd-deploy.bat，用文本编辑器打开,添加如下内容并保存。注意：python后面的改为自己电脑下Scripts目录下的scrapyd-deploy
@echo off
python D:\Christina\AppData\Local\Programs\Python\Python36-32\Scripts\scrapyd-deploy %*
1
2
相关API使用
查看服务进程状态
GET　http://127.0.0.1:6800/daemonstatus.json
1
可查看当前的运行状态：将要执行的任务数、运行中的任务数、已经结束的任务数。如我用postman请求返回的结果



项目发布版本
推荐使用上面的scrapyd-deploy发布。

POST http://127.0.0.1:6800/addversion.json
1
参数：

project(string, required)，项目名称；
version(string, required)，项目版本；
egg (file, required)，打包的项目文件。
调度爬虫
调度爬虫的运行，返回任务id。

POST http://127.0.0.1:6800/schedule.json
1
参数：

project (string, required)，项目名称。
spider (string, required)，爬虫名称，即 Spider下的name属性指定的。即scrapy crawl [爬虫名称]运行时的名称。
setting (string, optional)，运行时的设置文件，默认为项目下settings.py。
jobid (string, optional)，任务id，不指定则为默认生成的UUID。
_version (string, optional)，运行的项目的版本。
任何其他的参数都被传递给爬虫的属性，即scrapy crawl [爬虫名称] -a accounts=testAdmin后面-a所带的参数，在Spider中可通过self.testAdmin来获取值。
小编通过postman访问，如下，返回的jobid可用于查看任务状态，取消任务。



取消任务
利用调度运行时返回的jobid来取消。

POST http://localhost:6800/cancel.json
1
参数：

project (string, required)，项目名称。
job (string, required)，任务id。


获取上传的项目
Scrapyd可管理多个Scrapy项目，可通过此方法获取上传的项目。

GET http://127.0.0.1:6800/listprojects.json
1


获取项目的版本
返回上传的项目的版本列表，最后一个为当前版本。

GET http://127.0.0.1:6800/listversions.json
1
参数：

project (string, required)，项目名称。


获取项目的爬虫列表
返回指定版本，如不指定则为最新版本的可用爬虫列表。

GET http://127.0.0.1:6800/listspiders.json
1
参数：

project (string, required)，项目名称。
_version (string, optional)，运行的项目的版本。


获取任务列表（Scrapyd 0.15版本以上）
获取指定项目的将要执行的、正在运行的、已经结束的任务

GET http://127.0.0.1:6800/listjobs.json
1
参数：

project (string, required)，项目名称。


删除项目版本
删除指定项目的指定版本，注意：当项目没有其他版本可以使用时，项目也会被删除。

POST http://127.0.0.1:6800/delversion.json
1
参数：

project (string, required) 项目名称。
version (string, required) 要删除项目的版本


删除项目
删除一个项目及所有上传的版本。

POST http://127.0.0.1:6800/delproject.json
1
参数：

project (string, required) 项目名称。


本文结束啦--------
————————————————
版权声明：本文为CSDN博主「所谓向日葵族」的原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/weixin_38601833/article/details/100694008
